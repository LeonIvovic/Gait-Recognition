{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMsFKIILtrk4"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHNj_9hktrAU",
        "outputId": "d07f6f27-c1bc-4385-d54b-f9a4f4e761c4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnEVtJFmrhRw"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "rfPmIWL3rgg5",
        "outputId": "b9d148d3-e5d7-46d3-aba5-727638b0c7b2"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "from torch.nn.modules import loss\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU available \" + torch.cuda.torch.cuda.get_device_name())\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class GaitImage():\n",
        "    def __init__(self, path, subject):           \n",
        "        self.image = Image.open(path)\n",
        "        self.subject = int(subject)\n",
        "\n",
        "class GaitImageDataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        self.images = images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def getSubjects(self):\n",
        "        unique_subjects = set()\n",
        "\n",
        "        for img in self.images:\n",
        "            unique_subjects.add(img.subject)\n",
        "\n",
        "        return unique_subjects\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        gait_image = self.images[index]\n",
        "        image_PIL = gait_image.image\n",
        "\n",
        "        transform_to_tensor = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        image = transform_to_tensor(image_PIL).to(device)\n",
        "\n",
        "        label = torch.tensor(gait_image.subject)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def read_args():\n",
        "    arguments = sys.argv\n",
        "    dataset_arg = arguments[1]\n",
        "\n",
        "    if dataset_arg not in [\"oumvlp\", \"casiab74\"]:\n",
        "        raise ValueError(dataset_arg + \" not supported, only `oumvlp` and `casiab74` allowed\")\n",
        "\n",
        "    model_arg = arguments[2]\n",
        "\n",
        "    if model_arg not in [\"vgg16\", \"resnet18\", \"resnet50\"]:\n",
        "        raise ValueError(model_arg + \" not supported, only `vgg16`, `resnet18` and `resnet50` allowed\")\n",
        "\n",
        "    learning_rate = float(arguments[3])\n",
        "\n",
        "    if learning_rate < 0:\n",
        "        raise ValueError(\"Learning rate must be positive\")\n",
        "\n",
        "    max_epochs = int(arguments[4])\n",
        "\n",
        "    return dataset_arg, model_arg, learning_rate, max_epochs\n",
        "\n",
        "def load_datasets(dataset, batch_size=32, shuffle=True):\n",
        "    train_folder = Path(\"/content/\" + dataset +\"/ProcessedBySID/train\").resolve()\n",
        "    query_folder = Path(\"/content/\" + dataset +\"/ProcessedBySID/query\").resolve()\n",
        "\n",
        "    train_images = []\n",
        "    test_images = []\n",
        "\n",
        "    for img in sorted(train_folder.iterdir()):\n",
        "        train_images.append(GaitImage(img.as_posix(), img.name[:-8]))\n",
        "\n",
        "    train_dataset = GaitImageDataset(train_images)\n",
        "\n",
        "    for img in sorted(query_folder.iterdir()):\n",
        "        test_images.append(GaitImage(img.as_posix(), img.name[:-8]))\n",
        "\n",
        "    test_dataset = GaitImageDataset(test_images)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size,\n",
        "        shuffle\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size,\n",
        "        shuffle\n",
        "    )\n",
        "\n",
        "    print(\"BATCH SIZE:    \", batch_size)\n",
        "    \n",
        "    return train_dataset, test_dataset, train_loader, test_loader\n",
        "\n",
        "def get_model(model_arg, num_classes):\n",
        "    # Load model\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', model_arg)\n",
        "\n",
        "    if model_arg == \"vgg16\":\n",
        "        # Modify conv layer to work with grayscale images\n",
        "        model.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Get the number of input features to the original output layer\n",
        "        in_features = model.classifier[6].in_features\n",
        "\n",
        "        # Replace the last layer with a new fully connected layer\n",
        "        model.classifier[6] = nn.Linear(in_features, num_classes)\n",
        "    else:\n",
        "        # Modify conv layer to work with grayscale images\n",
        "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
        "\n",
        "        # Get the number of input features to the original output layer\n",
        "        in_features = model.fc.in_features\n",
        "\n",
        "        # Replace the last layer with a new fully connected layer\n",
        "        model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "def calculate_topk_accuracy(outputs, labels, k=1):\n",
        "    _, predicted = torch.topk(outputs, k, dim=1)\n",
        "    correct = torch.sum(predicted == labels.view(-1, 1))\n",
        "    accuracy = correct.item() / labels.size(0) * 100\n",
        "    return accuracy\n",
        "\n",
        "def train_one_epoch(model, optimizer, loss_fn, train_loader):\n",
        "    running_loss = 0.0\n",
        "    avg_acc = 0.0\n",
        "    avg_top5 = 0.0\n",
        "\n",
        "    correct_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Zero your gradients for every batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        last_loss = loss.detach().item()\n",
        "        running_loss += last_loss\n",
        "\n",
        "        # Calculate accuracy\n",
        "        top1_accuracy = calculate_topk_accuracy(outputs, labels, k=1)\n",
        "        top5_accuracy = calculate_topk_accuracy(outputs, labels, k=5)\n",
        "        avg_acc += top1_accuracy\n",
        "        avg_top5 += top5_accuracy\n",
        "\n",
        "        # Confusion matrix\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        correct_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print('     batch {} loss: {} top-1 accuracy: {:.2f}% top-5 accuracy: {:.2f}%'.format(i, last_loss, top1_accuracy, top5_accuracy))\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(correct_labels, predictions)\n",
        "    plt.figure(figsize=(18, 18))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return running_loss / len(train_loader), avg_acc / len(train_loader), avg_top5 / len(train_loader)\n",
        "\n",
        "def test_one_epoch(model, loss_fn, test_loader):\n",
        "    running_loss = 0.0\n",
        "    avg_acc = 0.0\n",
        "    avg_top5 = 0.0\n",
        "\n",
        "    for i, data in enumerate(test_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "       \n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Gather data and report\n",
        "        last_loss = loss.detach().item()\n",
        "        running_loss += last_loss\n",
        "\n",
        "        # Calculate accuracy\n",
        "        top1_accuracy = calculate_topk_accuracy(outputs, labels, k=1)\n",
        "        top5_accuracy = calculate_topk_accuracy(outputs, labels, k=5)\n",
        "        avg_acc += top1_accuracy\n",
        "        avg_top5 += top5_accuracy\n",
        "            \n",
        "        if i % 1000 == 0:\n",
        "            print('     batch {} loss: {} top-1 accuracy: {:.2f}% top-5 accuracy: {:.2f}%'.format(i, last_loss, top1_accuracy, top5_accuracy))\n",
        "\n",
        "    return running_loss / len(test_loader), avg_acc / len(test_loader), avg_top5 / len(test_loader)\n",
        "\n",
        "def main():\n",
        "    dataset, model_arg, lr, max_epochs = read_args()\n",
        "\n",
        "    print(\"---------------------INFO--------------------\")\n",
        "    print(\"DATASET:       \", dataset)\n",
        "    print(\"MODEL:         \", model_arg)\n",
        "    print(\"EPOCHS:        \", max_epochs)\n",
        "    print(\"LEARNING RATE: \", lr)\n",
        "\n",
        "    train_dataset, test_dataset, train_loader, test_loader = load_datasets(dataset, 32, True)\n",
        "\n",
        "    print(\"---------------------TRAIN--------------------\")\n",
        "    print(\"Dataset size:        \", len(train_dataset))\n",
        "    print(\"Unique classse size: \", len(train_dataset.getSubjects()))\n",
        "    print(\"---------------------TEST---------------------\")\n",
        "    print(\"Dataset size:        \", len(test_dataset))\n",
        "    print(\"Unique classse size: \", len(test_dataset.getSubjects()))\n",
        "    print(\"----------------------------------------------\")\n",
        "\n",
        "    model = get_model(model_arg, len(train_dataset.getSubjects()))\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    loss_fn.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr, weight_decay=0.001)\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        print(\"-------------------EPOCH {}------------------\".format(epoch + 1))\n",
        "\n",
        "        # Make sure gradient tracking is on, and do a pass over the data\n",
        "        model.train()\n",
        "        avg_loss, accuracy, top5_accuracy = train_one_epoch(model, optimizer, loss_fn, train_loader)\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            # Add any other information you want to save\n",
        "        }\n",
        "\n",
        "        if epoch % 20 == 0:\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                # Add any other information you want to save\n",
        "            }\n",
        "            # Specify the path where you want to save the checkpoint\n",
        "            checkpoint_path = model_arg + \"_\" + dataset + \"-\" + str(epoch)\n",
        "\n",
        "            # Save the checkpoint to the specified path\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "        # Set the model to evaluation mode, disabling dropout and using population\n",
        "        # statistics for batch normalization.\n",
        "        model.eval()\n",
        "\n",
        "        # Disable gradient computation and reduce memory consumption.\n",
        "        with torch.no_grad():\n",
        "            avg_vloss, vaccuracy, vaccuracy_top5 = test_one_epoch(model, loss_fn, test_loader)\n",
        "\n",
        "        print(\"------------------TRAIN------------------\")\n",
        "        print('Loss {} Accuracy: {:.2f}% Top-5 accuracy: {:.2f}%'.format(avg_loss, accuracy, top5_accuracy))\n",
        "        print(\"------------------TEST-------------------\")\n",
        "        print('Loss {} Accuracy: {:.2f}% Top-5 accuracy: {:.2f}%'.format(avg_vloss, vaccuracy, vaccuracy_top5))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4JA7jwA0-2s"
      },
      "source": [
        "# CASIA-B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlNgBOO5FXat"
      },
      "source": [
        "## Extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj4j50BUOfoL",
        "outputId": "fd72a753-8f4d-4e75-c745-3a5fd3a1f2c4"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/casiab.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VEtOJGIFXav"
      },
      "source": [
        "## Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0H4xcDDkujB"
      },
      "outputs": [],
      "source": [
        "from logging import currentframe\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "sourceFolder = Path(\"casiab74\").resolve()\n",
        "destinationFolder = \"/ProcessedBySID/\"\n",
        "totalFiles = 0\n",
        "currentFile = 0\n",
        "\n",
        "destPath = sourceFolder.as_posix() + destinationFolder\n",
        "Path.mkdir(Path(destPath), exist_ok = True)\n",
        "\n",
        "def ExtractWalkingStatus(name):\n",
        "    # Normal\n",
        "    if  \"nm\" in name: return \"nm\"\n",
        "    # In a coat\n",
        "    if  \"cl\" in name: return \"cl\"\n",
        "    # WIth a bag\n",
        "    if  \"bg\" in name: return \"bg\"\n",
        "    print(\"Error - Unknown walkign status: \" + name)\n",
        "\n",
        "def ProcessFile(src: Path, sid, ws, va, sn):\n",
        "    #print(\"Processing {}/{}: \".format(currentFile, totalFiles) + src.name + \" -> \" + subjectID + \"_\" + walkingStatus + \"_\" + viewAnge + \"_\" + sequenceNumber, flush=True)\n",
        "    shutil.copy(src, destPath + \"_\".join([sid, ws, va, sn]) + \".png\")\n",
        "\n",
        "def ProcessFile(category, src: Path, sid, i):\n",
        "    #print(\"Processing {}/{}: \".format(currentFile, totalFiles) + src.name + \" -> \" + subjectID + \"_\" + str(i).zfill(3), flush=True)\n",
        "    shutil.copy(src, destPath + \"/\" + category + \"/\"  + \"_\".join([str(sid).zfill(6), str(i).zfill(3)]) + \".png\")\n",
        "\n",
        "class DataImg(object):\n",
        "    def __init__(self, sid, ws, va, sn, cat):\n",
        "        self.subjectID = sid\n",
        "        self.walkingStatus = ws\n",
        "        self.viewAngle = va\n",
        "        self.sequenceNumber = sn\n",
        "        self.category = cat\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "CASIA-B format:\n",
        "\n",
        "CASIA-B Folder\n",
        "    gallery\n",
        "        subjectID1\n",
        "            nm000_000001.png\n",
        "            nm180_000002.png\n",
        "            ...\n",
        "\n",
        "        subjectID2\n",
        "            bg072_000001.png\n",
        "            bg090_000002.png\n",
        "            ...\n",
        "\n",
        "        ...\n",
        "    query\n",
        "        ...\n",
        "    train\n",
        "        ...\n",
        "\n",
        "Image name:\n",
        "WalkingStatusViewAngle_SequenceNumber.png\n",
        "\n",
        "Subject ID - 4 numbers\n",
        "Walking status - nm (normal), cl (in a coat), bg (with a bag)\n",
        "View angle - 3 numbers (in degrees 0 - 180)\n",
        "Sequence number - 2 numbers\n",
        "\"\"\"\n",
        "\n",
        "# Current folder contains Query, Train, Gallery\n",
        "\n",
        "# Count files\n",
        "totalFiles = 0\n",
        "for i in sourceFolder.rglob(\"*.png\"):\n",
        "    totalFiles += 1\n",
        "\n",
        "for category in sourceFolder.iterdir():\n",
        "    if not category.name in [\"gallery\", \"query\", \"train\"]: continue\n",
        "    Path.mkdir(Path(destPath + \"/\" + category.name), exist_ok = True)\n",
        "\n",
        "    subjectID = 0\n",
        "    for subject in category.iterdir():\n",
        "        #subjectID = subject.name.removeprefix(\"00\")\n",
        "        subjectCounter = 0\n",
        "        for image in subject.iterdir():\n",
        "            split = image.name.split(\"_\")\n",
        "            walkingStatus = ExtractWalkingStatus(split[0])\n",
        "            viewAngle = split[0].removeprefix(walkingStatus)\n",
        "            sequenceNumber = split[1].removesuffix(\".png\").removeprefix(\"000\")\n",
        "\n",
        "            ProcessFile(category.name, image, subjectID, subjectCounter)\n",
        "            subjectCounter += 1\n",
        "            #ProcessFile(image, subjectID, walkingStatus, viewAngle, sequenceNumber)\n",
        "            currentFile +=1\n",
        "        if subjectCounter > 0:\n",
        "            subjectID += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ3njmD8FXax"
      },
      "source": [
        "## Train\n",
        "data_loader arguments: `dataset` `model` `learning_rate` `epochs`\n",
        "- Datasets: `oumvlp`, `casiab74`\n",
        "- Models: `vgg16`, `resnet18`, `resnet50`\n",
        "- Learning rate: positive float\n",
        "- Epochs: positive int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Wmx8DbFXax"
      },
      "source": [
        "### VGGNet 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9XI5nwdFXax",
        "outputId": "98119d01-cd7e-441b-fd6e-2a03eba8b958"
      },
      "outputs": [],
      "source": [
        "!python data_loader.py \"casiab74\" \"vgg16\" 0.00001 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5grM9k3FXaz"
      },
      "source": [
        "### ResNet 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYfpSjfBFXaz",
        "outputId": "4b6d0d8a-7c9a-47d5-f3eb-b324c77ace28"
      },
      "outputs": [],
      "source": [
        "!python data_loader.py \"casiab74\" \"resnet18\" 0.00001 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUfd-xDVFXa0"
      },
      "source": [
        "### ResNet 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfgeOhFBFXa1",
        "outputId": "bbd95ace-d049-4972-9cee-6933a5d98c3f"
      },
      "outputs": [],
      "source": [
        "!python data_loader.py \"casiab74\" \"resnet50\" 0.0001 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDBhsE0k1F1K"
      },
      "source": [
        "# OUMVLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOUVJ6SHFXa2"
      },
      "source": [
        "## Extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDJOqHD61FVT",
        "outputId": "a93fcd7d-36f9-4070-de30-b915c94d6a72"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/oumvlp.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yLIUbd0FXa2"
      },
      "source": [
        "## Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd6W6QTn1H-D",
        "outputId": "e00d85c9-42aa-43df-d723-6120bc37b66e"
      },
      "outputs": [],
      "source": [
        "from logging import currentframe\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "sourceFolder = Path(\"oumvlp\").resolve()\n",
        "destinationFolder = \"/ProcessedBySID/\"\n",
        "totalFiles = 0\n",
        "currentFile = 0\n",
        "\n",
        "destPath = sourceFolder.as_posix() + destinationFolder\n",
        "Path.mkdir(Path(destPath), exist_ok = True)\n",
        "\n",
        "\n",
        "def ProcessFile(src: Path, sid, ws, va, sn):\n",
        "    #print(\"Processing {}/{}: \".format(currentFile, totalFiles) + src.name + \" -> \" + subjectID + \"_\" + walkingStatus + \"_\" + viewAnge + \"_\" + sequenceNumber, flush=True)\n",
        "    shutil.copy(src, destPath + \"_\".join([sid, ws, va, sn]) + \".png\")\n",
        "\n",
        "def ProcessFile(category, src: Path, sid, i):\n",
        "    print(\"Processing {} {}/{}: \".format(category, currentFile, totalFiles) + src.name + \" -> \" + \"_\".join([str(sid).zfill(6), str(i).zfill(3)]), flush=True)\n",
        "    shutil.copy(src, destPath + \"/\" + category + \"/\" + \"_\".join([str(sid).zfill(6), str(i).zfill(3)]) + \".png\")\n",
        "\n",
        "class DataImg(object):\n",
        "    def __init__(self, sid, ws, va, sn, cat):\n",
        "        self.subjectID = sid\n",
        "        self.walkingStatus = ws\n",
        "        self.viewAngle = va\n",
        "        self.sequenceNumber = sn\n",
        "        self.category = cat\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "OUMVLP format:\n",
        "\n",
        "OUMVLP Folder\n",
        "    gallery\n",
        "        subjectID1\n",
        "            000_000001.png\n",
        "            180_000002.png\n",
        "            ...\n",
        "\n",
        "        subjectID2\n",
        "            210_000001.png\n",
        "            270_000002.png\n",
        "            ...\n",
        "\n",
        "        ...\n",
        "    query\n",
        "        ...\n",
        "    train\n",
        "        ...\n",
        "\n",
        "Image name:\n",
        "ViewAngle_SequenceNumber.png\n",
        "\n",
        "Subject ID - 4 numbers\n",
        "View angle - 3 numbers (in degrees 0 - 180)\n",
        "\"\"\"\n",
        "\n",
        "# Current folder contains Query, Train, Gallery\n",
        "\n",
        "# Count files\n",
        "totalFiles = 0\n",
        "for i in sourceFolder.rglob(\"*.png\"):\n",
        "    totalFiles += 1\n",
        "\n",
        "for category in sourceFolder.iterdir():\n",
        "    if not category.name in [\"gallery\", \"query\", \"train\"]: continue\n",
        "    Path.mkdir(Path(destPath + \"/\" + category.name), exist_ok = True)\n",
        "\n",
        "    subjectID = 0\n",
        "    for subject in category.iterdir():\n",
        "        subjectCounter = 0\n",
        "        for image in subject.iterdir():\n",
        "            split = image.name.split(\"_\")\n",
        "\n",
        "            ProcessFile(category.name, image, subjectID, subjectCounter)\n",
        "\n",
        "            subjectCounter += 1\n",
        "            currentFile +=1\n",
        "        if subjectCounter > 0:\n",
        "            subjectID += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7qpI9f4FXa3"
      },
      "source": [
        "## Train\n",
        "data_loader arguments: `dataset` `model` `learning_rate` `epochs`\n",
        "- Datasets: `oumvlp`, `casiab74`\n",
        "- Models: `vgg16`, `resnet18`, `resnet50`\n",
        "- Learning rate: positive float\n",
        "- Epochs: positive int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Af450iGFXa3"
      },
      "source": [
        "### VGGNet 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AycDYrhFXa3"
      },
      "outputs": [],
      "source": [
        "!python data_loader.py \"oumvlp\" \"vgg16\" 0.00001 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tj-iWivFXa4"
      },
      "source": [
        "### ResNet 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEi0jvv5FXa4"
      },
      "outputs": [],
      "source": [
        "!python data_loader.py \"oumvlp\" \"resnet18\" 0.0001 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejiwCQwmFXa5"
      },
      "source": [
        "### ResNet 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq5CP5k_FXa5"
      },
      "outputs": [],
      "source": [
        "!python data_loader.py \"oumvlp\" \"resnet50\" 0.0001 40"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WlNgBOO5FXat",
        "pDBhsE0k1F1K",
        "NOUVJ6SHFXa2"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
